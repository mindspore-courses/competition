# main.py (é›†æˆHyDEç­–ç•¥)

import os
import time
import logging
from datetime import datetime
from typing import List, Dict

import streamlit as st
import ray

from ray_tasks import EmbeddingActor, LLMActor, parse_and_chunk_document

# RAY å’Œ MinIO è¿æ¥é…ç½®
RAY_ADDRESS = os.getenv("RAY_ADDRESS", "ray://127.0.0.1:10001")
MINIO_HOST = os.getenv("MINIO_HOST", "minio:9000")
MINIO_ACCESS_KEY = os.getenv("MINIO_ACCESS_KEY", "minioadmin")
MINIO_SECRET_KEY = os.getenv("MINIO_SECRET_KEY", "minioadmin")
MILVUS_HOST = os.getenv("MILVUS_HOST", "standalone")
MILVUS_PORT = os.getenv("MILVUS_PORT", "19530")
MINIO_BUCKET_NAME = "rag-documents"
MAX_OPTIMIZATION_ATTEMPTS = 2

# --- æ—¥å¿—é…ç½® ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# ==============================================================================
# 1. åˆå§‹åŒ– Ray è¿æ¥
# ==============================================================================
try:
    if not ray.is_initialized():
        logging.info(f"æ­£åœ¨è¿æ¥åˆ° Ray é›†ç¾¤: {RAY_ADDRESS}")
        ray.init(address=RAY_ADDRESS, ignore_reinit_error=True)
        logging.info("âœ… Ray è¿æ¥æˆåŠŸ!")
except Exception as e:
    logging.error(f"âŒ æ— æ³•è¿æ¥åˆ° Ray é›†ç¾¤: {e}")
    st.error(f"ä¸¥é‡é”™è¯¯ï¼šæ— æ³•è¿æ¥åˆ° Ray è®¡ç®—é›†ç¾¤ï¼Œè¯·æ£€æŸ¥ Ray Head æœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œã€‚é”™è¯¯è¯¦æƒ…: {e}")
    st.stop()


# ==============================================================================
# 2. MilvusClient ç±» 
# ==============================================================================
class MilvusClient:
    def __init__(self, host, port):
        from pymilvus import connections, utility, FieldSchema, CollectionSchema, DataType, Collection
        self.connections, self.utility, self.Collection = connections, utility, Collection
        self.DataType, self.FieldSchema, self.CollectionSchema = DataType, FieldSchema, CollectionSchema
        for i in range(5):
            try:
                self.connections.connect("default", host=host, port=port)
                logging.info("âœ… Milvus è¿æ¥æˆåŠŸã€‚")
                return
            except Exception as e:
                logging.warning(f"Milvus è¿æ¥å°è¯• {i+1}/5 å¤±è´¥... Error: {e}")
                time.sleep(3)
        raise ConnectionError("é”™è¯¯ï¼šå¤šæ¬¡å°è¯•åæ— æ³•è¿æ¥åˆ°Milvusã€‚")

    def create_or_get_collection(self, collection_name: str, dim: int = 768) -> 'Collection':
        if self.utility.has_collection(collection_name):
            return self.Collection(collection_name)
        fields = [
            self.FieldSchema(name="pk", dtype=self.DataType.VARCHAR, is_primary=True, auto_id=True, max_length=100),
            self.FieldSchema(name="text", dtype=self.DataType.VARCHAR, max_length=65535),
            self.FieldSchema(name="embedding", dtype=self.DataType.FLOAT_VECTOR, dim=dim)
        ]
        schema = self.CollectionSchema(fields, "RAGçŸ¥è¯†åº“é›†åˆ")
        collection = self.Collection(name=collection_name, schema=schema)
        index_params = {"index_type": "IVF_FLAT", "metric_type": "L2", "params": {"nlist": 1024}}
        collection.create_index(field_name="embedding", index_params=index_params)
        return collection

    def insert(self, collection_name: str, texts: List[str], vectors: List[List[float]]):
        collection = self.create_or_get_collection(collection_name)
        collection.insert([texts, vectors])
        collection.flush()

    def search(self, collection_name: str, query_vector: List[List[float]], top_k: int = 3) -> List[str]:
        if not self.utility.has_collection(collection_name):
            return ["é”™è¯¯ï¼šçŸ¥è¯†åº“é›†åˆä¸å­˜åœ¨ã€‚"]
        collection = self.Collection(collection_name)
        collection.load()
        search_params = {"metric_type": "L2", "params": {"nprobe": 10}}
        results = collection.search(data=query_vector, anns_field="embedding", param=search_params, limit=top_k, output_fields=["text"])
        return [hit.entity.get('text') for hit in results[0]] if results else []

# ==============================================================================
# 3. RAG Prompt æ¨¡æ¿ 
# ==============================================================================
RELEVANCE_ASSESSMENT_TEMPLATE = """ä½ æ˜¯ä¸€ä¸ªæ–‡æ¡£ç›¸å…³æ€§è¯„ä¼°å‘˜ã€‚è¯·åˆ¤æ–­ä¸‹é¢æä¾›çš„ã€æ–‡æ¡£ç‰‡æ®µã€‘æ˜¯å¦èƒ½å¸®åŠ©å›ç­”ã€ç”¨æˆ·é—®é¢˜ã€‘ã€‚
è¯·åªå›ç­”â€œæ˜¯â€æˆ–â€œå¦â€ã€‚

ã€ç”¨æˆ·é—®é¢˜ã€‘
{question}

ã€æ–‡æ¡£ç‰‡æ®µã€‘
---
{document}
---

ã€è¯¥æ–‡æ¡£æ˜¯å¦ç›¸å…³ï¼Ÿã€‘
"""

QUERY_OPTIMIZATION_TEMPLATE = """ä½ æ˜¯ä¸€ä¸ªæœç´¢å¼•æ“ä¼˜åŒ–ä¸“å®¶ã€‚å½“å‰çš„ç”¨æˆ·é—®é¢˜åœ¨çŸ¥è¯†åº“ä¸­æ²¡æœ‰æ£€ç´¢åˆ°ç›¸å…³çš„ç»“æœã€‚
è¯·ä½ æ¢ä¸€ä¸ªè§’åº¦ï¼Œä½¿ç”¨ä¸åŒçš„å…³é”®è¯æˆ–è¡¨è¾¾æ–¹å¼ï¼Œé‡æ–°ç”Ÿæˆä¸€ä¸ªä¸åŸé—®é¢˜æ„å›¾ç›¸åŒï¼Œä½†å¯èƒ½æ›´å®¹æ˜“åœ¨æ•°æ®åº“ä¸­åŒ¹é…åˆ°å†…å®¹çš„æ–°é—®é¢˜ã€‚
è¯·åªæä¾›ä¼˜åŒ–åçš„æ–°é—®é¢˜ï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šã€‚

ã€åŸå§‹é—®é¢˜ã€‘
{question}

ã€ä¼˜åŒ–åçš„æ–°é—®é¢˜ã€‘
"""

FINAL_ANSWER_TEMPLATE = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šã€ä¸¥è°¨çš„é—®ç­”åŠ©æ‰‹ã€‚è¯·æ ¹æ®ä¸‹é¢æä¾›çš„ã€å¯å‚è€ƒçš„ä¸Šä¸‹æ–‡ã€‘æ¥å›ç­”ç”¨æˆ·çš„ã€é—®é¢˜ã€‘ã€‚
ä½ çš„å›ç­”å¿…é¡»éµå¾ªä»¥ä¸‹è§„åˆ™ï¼š
1.  å®Œå…¨åŸºäºæä¾›çš„ä¸Šä¸‹æ–‡è¿›è¡Œå›ç­”ï¼Œç¦æ­¢ä½¿ç”¨ä»»ä½•å¤–éƒ¨çŸ¥è¯†æˆ–è¿›è¡ŒçŒœæµ‹ã€‚
2.  å¦‚æœä¸Šä¸‹æ–‡å†…å®¹è¶³ä»¥å›ç­”é—®é¢˜ï¼Œè¯·æ¸…æ™°ã€å‡†ç¡®åœ°ç»„ç»‡ç­”æ¡ˆã€‚
3.  å¦‚æœä¸Šä¸‹æ–‡å†…å®¹ä¸ç›¸å…³æˆ–ä¸è¶³ä»¥å›ç­”é—®é¢˜ï¼Œè¯·æ˜ç¡®æŒ‡å‡ºï¼šâ€œæ ¹æ®æ‚¨æä¾›çš„æ–‡æ¡£ï¼Œæˆ‘æ— æ³•æ‰¾åˆ°å…³äºè¿™ä¸ªé—®é¢˜çš„ç¡®åˆ‡ä¿¡æ¯ã€‚â€
4.  å›ç­”æ—¶è¯·ä¿æŒå®¢è§‚ã€ä¸“ä¸šçš„å£å»ï¼Œå¹¶ä¸”æ€»æ˜¯ä½¿ç”¨ä¸­æ–‡ã€‚

ã€é—®é¢˜ã€‘
{question}

ã€å¯å‚è€ƒçš„ä¸Šä¸‹æ–‡ã€‘
---
{context}
---

ã€ä½ çš„å›ç­”ã€‘
"""

# --- æ–°å¢ï¼šHyDE ç­”æ¡ˆç”Ÿæˆ Prompt ---
HYDE_PROMPT_TEMPLATE = """ä½ æ˜¯ä¸€ä¸ªå–„äºå›ç­”é—®é¢˜çš„åŠ©æ‰‹ã€‚è¯·æ ¹æ®ç”¨æˆ·çš„ã€é—®é¢˜ã€‘ï¼Œç”Ÿæˆä¸€ä¸ªè¯¦ç»†ã€å®Œæ•´ã€çœ‹èµ·æ¥éå¸¸ä¸“ä¸šçš„å›ç­”ã€‚
é‡è¦æç¤ºï¼šè¿™ä¸ªå›ç­”æ˜¯ç”¨äºåç»­æ£€ç´¢çš„ï¼Œæ‰€ä»¥å®ƒä¸éœ€è¦ä¿è¯äº‹å®çš„ç»å¯¹æ­£ç¡®æ€§ï¼Œä½†å¿…é¡»ä¸é—®é¢˜é«˜åº¦ç›¸å…³ï¼Œå¹¶ä¸”åœ¨æ ¼å¼å’Œæªè¾ä¸Šåƒä¸€ç¯‡çœŸå®çš„æ–‡æ¡£ç‰‡æ®µã€‚

ã€é—®é¢˜ã€‘
{question}

ã€è¯·ç”Ÿæˆä¸€ä¸ªå‡æƒ³çš„ã€ç”¨äºæ£€ç´¢çš„ç­”æ¡ˆã€‘
"""

# ==============================================================================
# 4. é›†æˆHyDEçš„RAGæµç¨‹
# ==============================================================================
def execute_rag_pipeline_ray(files_data: List[Dict], query: str, use_hyde: bool) -> Dict:
    logging.info("ğŸš€ ======== å¼€å§‹æ‰§è¡ŒRAGå·¥ä½œæµ ========")
    
    # --- 1. è·å– Actor å¥æŸ„ ---
    try:
        embedding_actor = ray.get_actor("EmbeddingActor")
        llm_actor = ray.get_actor("LLMActor")
        logging.info("âœ… Actor å¥æŸ„è·å–æˆåŠŸã€‚")
    except ValueError:
        logging.warning("Actor æœªæ‰¾åˆ°ï¼Œæ­£åœ¨åˆ›å»ºæ–°çš„ Actor å®ä¾‹...")
        embedding_actor = EmbeddingActor.options(name="EmbeddingActor", get_if_exists=True).remote()
        llm_actor = LLMActor.options(name="LLMActor", get_if_exists=True).remote()
        logging.info("âœ… æ–°çš„ Actor å®ä¾‹å·²åˆ›å»ºã€‚")

    # --- 2. æ–‡ä»¶è§£æä¸HyDEå¹¶è¡Œæ‰§è¡Œ ---
    parse_tasks = [parse_and_chunk_document.remote(f['content'], f['name']) for f in files_data]
    logging.info(f"æäº¤äº† {len(parse_tasks)} ä¸ªæ–‡ä»¶è§£æä»»åŠ¡åˆ° Rayã€‚")
    
    hypothetical_answer_ref = None
    if use_hyde:
        logging.info("ğŸ’¡ HyDEç­–ç•¥å·²å¯ç”¨ï¼Œæ­£åœ¨ç”Ÿæˆå‡æƒ³ç­”æ¡ˆ...")
        hyde_prompt = HYDE_PROMPT_TEMPLATE.format(question=query)
        hypothetical_answer_ref = llm_actor.generate.remote(hyde_prompt)

    # --- 3. å‘é‡åŒ–ã€å­˜å‚¨å’Œæ£€ç´¢ (åŒ…å«é‡è¯•å¾ªç¯) ---
    milvus_client = MilvusClient(host=MILVUS_HOST, port=MILVUS_PORT)
    parsed_results = ray.get(parse_tasks)
    all_chunks = [chunk for result in parsed_results for chunk in result]
    
    if not all_chunks:
        return {"answer": "âŒ æœªèƒ½ä»ä»»ä½•æ–‡ä»¶ä¸­æå–æ–‡æœ¬å—ã€‚", "hypothetical_answer": ""}

    logging.info(f"æ‰€æœ‰æ–‡ä»¶è§£æå®Œæˆï¼Œå…±å¾—åˆ° {len(all_chunks)} ä¸ªæ–‡æœ¬å—ã€‚")
    chunk_vectors_ref = embedding_actor.embed.remote(all_chunks)
    
    # --- è·å–HyDEç»“æœå¹¶ç¡®å®šåˆæ¬¡æ£€ç´¢æ–‡æœ¬ ---
    hypothetical_answer = ""
    if use_hyde and hypothetical_answer_ref:
        hypothetical_answer = ray.get(hypothetical_answer_ref).strip()
        logging.info(f"ğŸ“ ç”Ÿæˆçš„å‡æƒ³ç­”æ¡ˆ: '{hypothetical_answer[:100]}...'")
        retrieval_text = hypothetical_answer
    else:
        retrieval_text = query

    current_query = query # ä¿å­˜åŸå§‹é—®é¢˜ï¼Œç”¨äºç›¸å…³æ€§è¯„ä¼°å’Œæœ€ç»ˆç”Ÿæˆ
    
    for attempt in range(MAX_OPTIMIZATION_ATTEMPTS + 1):
        logging.info(f"--- ç¬¬ {attempt + 1} æ¬¡å°è¯• ---")
        
        # ä¼˜åŒ–åï¼Œä½¿ç”¨ä¼˜åŒ–æŸ¥è¯¢è¿›è¡Œæ£€ç´¢
        if attempt > 0:
            retrieval_text = current_query

        logging.info(f"å½“å‰ç”¨äºæ£€ç´¢çš„æ–‡æœ¬: '{retrieval_text[:100]}...'")
        
        query_vector_ref = embedding_actor.embed.remote([retrieval_text])
        query_vector, chunk_vectors = ray.get([query_vector_ref, chunk_vectors_ref])
        
        if not chunk_vectors or not query_vector:
            return {"answer": "âŒ å‘é‡åŒ–å¤±è´¥ï¼Œè¯·æ£€æŸ¥ EmbeddingActor çš„æ—¥å¿—ã€‚", "hypothetical_answer": hypothetical_answer}
        
        if attempt == 0:
            collection_name = f"rag_session_{datetime.now().strftime('%Y%m%d%H%M%S')}"
            milvus_client.insert(collection_name, all_chunks, chunk_vectors)
            logging.info(f"å·²å°† {len(all_chunks)} ä¸ªå‘é‡å­˜å…¥ Milvus é›†åˆ '{collection_name}'ã€‚")

        retrieved_docs = milvus_client.search(collection_name, query_vector)
        
        # --- 4. ç›¸å…³æ€§è¯„ä¼° ---
        if retrieved_docs:
            assessment_tasks = [
                llm_actor.generate.remote(
                    RELEVANCE_ASSESSMENT_TEMPLATE.format(question=current_query, document=doc)
                ) for doc in retrieved_docs
            ]
            assessment_results = ray.get(assessment_tasks)
            
            relevant_docs = [doc for doc, assessment in zip(retrieved_docs, assessment_results) if "æ˜¯" in assessment.strip()]
            logging.info(f"æ£€ç´¢åˆ° {len(retrieved_docs)} ç¯‡æ–‡æ¡£ï¼Œå…¶ä¸­ {len(relevant_docs)} ç¯‡é€šè¿‡ç›¸å…³æ€§è¯„ä¼°ã€‚")

            if relevant_docs:
                context = "\n---\n".join(relevant_docs)
                final_prompt = FINAL_ANSWER_TEMPLATE.format(question=query, context=context)
                logging.info("æäº¤æœ€ç»ˆç­”æ¡ˆç”Ÿæˆä»»åŠ¡ã€‚")
                final_response = ray.get(llm_actor.generate.remote(final_prompt))
                logging.info("ğŸ ======== Ray RAG å·¥ä½œæµæ‰§è¡Œå®Œæ¯• ========")
                return {"answer": final_response, "hypothetical_answer": hypothetical_answer}
        
        # --- 5. æŸ¥è¯¢ä¼˜åŒ– ---
        if attempt < MAX_OPTIMIZATION_ATTEMPTS:
            logging.warning("æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£ï¼Œæ­£åœ¨å°è¯•ä¼˜åŒ–æŸ¥è¯¢...")
            optimization_prompt = QUERY_OPTIMIZATION_TEMPLATE.format(question=current_query)
            optimized_query = ray.get(llm_actor.generate.remote(optimization_prompt)).strip()
            if optimized_query and optimized_query != current_query:
                current_query = optimized_query
            else:
                logging.error("æŸ¥è¯¢ä¼˜åŒ–å¤±è´¥ï¼Œæ— æ³•ç”Ÿæˆæ–°çš„æŸ¥è¯¢ã€‚")
                break
        else:
            logging.warning("å·²è¾¾åˆ°æœ€å¤§ä¼˜åŒ–æ¬¡æ•°ã€‚")

    return {
        "answer": "æŠ±æ­‰ï¼Œåœ¨æ‚¨æä¾›çš„æ–‡æ¡£ä¸­ï¼Œæˆ‘å¤šæ¬¡å°è¯•åä»æœªæ‰¾åˆ°èƒ½å›ç­”æ‚¨é—®é¢˜çš„ç›¸å…³ä¿¡æ¯ã€‚",
        "hypothetical_answer": hypothetical_answer
    }

# ==============================================================================
# 5. Streamlit ç•Œé¢ (é›†æˆHyDEå¼€å…³å’Œæ…¢æ€è€ƒå±•ç¤º)
# ==============================================================================
def run_streamlit_app():
    st.set_page_config(page_title="åˆ†å¸ƒå¼RAGåº”ç”¨ (Rayç‰ˆ)", layout="wide")
    st.title("ğŸš€ åˆ†å¸ƒå¼RAGåº”ç”¨ (Ray ç»Ÿä¸€è®¡ç®—åç«¯)")
    st.markdown("ä¸Šä¼ æ–‡ä»¶å¹¶æé—®ï¼Œç³»ç»Ÿå°†é€šè¿‡ Ray åˆ†å¸ƒå¼åç«¯å¹¶è¡Œå¤„ç†æ•°æ®å¹¶ç”Ÿæˆå›ç­”ã€‚")

    # --- åˆå§‹åŒ–ä¼šè¯çŠ¶æ€ ---
    if "response" not in st.session_state:
        st.session_state.response = "è¯·åœ¨ä¸‹æ–¹æäº¤é—®é¢˜å’Œæ–‡ä»¶ï¼Œæˆ‘ä¼šåœ¨è¿™é‡Œç»™å‡ºå›ç­”..."
    if "hypothetical_answer" not in st.session_state:
        st.session_state.hypothetical_answer = ""

    # --- é«˜çº§é€‰é¡¹ä¾§è¾¹æ  ---
    with st.sidebar:
        st.subheader("âš™ï¸ é«˜çº§é€‰é¡¹")
        use_hyde = st.toggle("å¯ç”¨HyDEç­–ç•¥", value=True, help="é€šè¿‡ç”Ÿæˆå‡æƒ³ç­”æ¡ˆæ¥ä¼˜åŒ–æ£€ç´¢ï¼Œå¯èƒ½æå‡ç›¸å…³æ€§ä½†ä¼šå¢åŠ å°‘é‡å»¶è¿Ÿã€‚")

    # --- è¾“å…¥è¡¨å• ---
    with st.form("rag_form"):
        query = st.text_input(
            "è¯·è¾“å…¥ä½ çš„é—®é¢˜:",
            placeholder="ä¾‹å¦‚ï¼šè¿™ä»½æ–‡æ¡£çš„æ ¸å¿ƒå†…å®¹æ˜¯ä»€ä¹ˆï¼Ÿ"
        )
        
        uploaded_files = st.file_uploader(
            "ä¸Šä¼ çŸ¥è¯†åº“æ–‡ä»¶ï¼ˆæ”¯æŒå›¾ç‰‡ã€PDFã€Markdownã€æ–‡æœ¬ï¼‰ï¼Œå¯å¤šé€‰: ğŸ–¼ï¸",
            accept_multiple_files=True,
            type=['png', 'jpg', 'jpeg', 'md', 'txt', 'pdf']
        )
        
        submit_button = st.form_submit_button("æäº¤")

    # --- é€»è¾‘å¤„ç† ---
    if submit_button:
        if query and uploaded_files:
            with st.spinner("ç³»ç»Ÿæ­£åœ¨é€šè¿‡ Ray åˆ†å¸ƒå¼åç«¯å¤„ç†ä¸­..."):
                try:
                    files_data = [{'name': f.name, 'content': f.getvalue()} for f in uploaded_files]
                    
                    logging.info(f"Streamlit æ¥æ”¶åˆ°æŸ¥è¯¢: '{query}' å’Œ {len(files_data)} ä¸ªæ–‡ä»¶ã€‚")
                    # è°ƒç”¨RAGæµç¨‹ï¼Œå¹¶ä¼ å…¥HyDEå¼€å…³çŠ¶æ€
                    result_dict = execute_rag_pipeline_ray(files_data=files_data, query=query, use_hyde=use_hyde)
                    
                    st.session_state.response = result_dict.get("answer", "æœªèƒ½è·å–å›ç­”ã€‚")
                    st.session_state.hypothetical_answer = result_dict.get("hypothetical_answer", "")
                except Exception as e:
                    error_message = f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}"
                    st.error(error_message)
                    st.session_state.response = error_message
                    logging.error(f"Streamlit UIå±‚æ•è·åˆ°å¼‚å¸¸: {e}", exc_info=True)
        else:
            st.error("é”™è¯¯ï¼šè¯·ç¡®ä¿æ‚¨å·²è¾“å…¥é—®é¢˜å¹¶ä¸Šä¼ äº†æ–‡ä»¶ã€‚")

    # --- å±•ç¤ºâ€œæ…¢æ€è€ƒâ€è¿‡ç¨‹ ---
    if st.session_state.hypothetical_answer:
        with st.expander("ğŸ” æŸ¥çœ‹â€œæ…¢æ€è€ƒâ€è¿‡ç¨‹ (HyDEç”Ÿæˆçš„å‡æƒ³ç­”æ¡ˆ)"):
            st.info(st.session_state.hypothetical_answer)

    # --- æ˜¾ç¤ºæœ€ç»ˆå›ç­” ---
    st.subheader("æ¨¡å‹çš„å›ç­”:")
    st.text_area("", value=st.session_state.response, height=400, disabled=True, label_visibility="collapsed")


if __name__ == "__main__":
    run_streamlit_app()