# main_app/main.py

import requests
import os
import PyPDF2
import markdown
from bs4 import BeautifulSoup
import re
import tiktoken
import time
import logging
from datetime import datetime
from typing import List, Dict

# ------------------- Streamlitç›¸å…³ä¾èµ– -------------------
import streamlit as st
import tempfile # ç”¨äºå¤„ç†Streamlitä¸Šä¼ çš„æ–‡ä»¶

EMBEDDING_SERVER_URL = os.getenv("EMBEDDING_SERVER_URL", "http://embedding-server/embed")
LLM_SERVER_URL = os.getenv("LLM_SERVER_URL", "http://llm-server/generate")
MINIO_HOST = os.getenv("MINIO_HOST", "minio:9000")
MINIO_ACCESS_KEY = os.getenv("MINIO_ACCESS_KEY", "minioadmin")
MINIO_SECRET_KEY = os.getenv("MINIO_SECRET_KEY", "minioadmin")
MILVUS_HOST = os.getenv("MILVUS_HOST", "standalone")
MILVUS_PORT = os.getenv("MILVUS_PORT", "19530")
MINIO_BUCKET_NAME = "rag-documents"

enc = tiktoken.get_encoding("cl100k_base")
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

class FileProcessor:
    """
    æ–‡ä»¶å¤„ç†å·¥å…·ç±»ï¼Œæ”¯æŒPDFã€Markdownã€TXTç­‰æ ¼å¼çš„è¯»å–ä¸åˆ†å—ã€‚
    """
    @staticmethod
    def read_pdf(file_stream) -> str:
        """
        è¯»å–PDFæ–‡ä»¶å†…å®¹ï¼Œè¿”å›çº¯æ–‡æœ¬ã€‚
        """
        reader = PyPDF2.PdfReader(file_stream)
        text = "".join(page.extract_text() for page in reader.pages)
        return text
    @staticmethod
    def read_markdown(file_stream) -> str:
        """
        è¯»å–Markdownæ–‡ä»¶å†…å®¹ï¼Œè½¬ä¸ºçº¯æ–‡æœ¬ã€‚
        """
        md_text = file_stream.read().decode('utf-8')
        html_text = markdown.markdown(md_text)
        soup = BeautifulSoup(html_text, 'html.parser')
        plain_text = soup.get_text()
        return re.sub(r'http\S+', '', plain_text)
    @staticmethod
    def read_text(file_stream) -> str:
        """
        è¯»å–TXTæ–‡ä»¶å†…å®¹ï¼Œè¿”å›å­—ç¬¦ä¸²ã€‚
        """
        return file_stream.read().decode('utf-8')
    @classmethod
    def read_file_content(cls, file_stream, file_name: str) -> str:
        """
        æ ¹æ®æ–‡ä»¶æ‰©å±•åè‡ªåŠ¨é€‰æ‹©è¯»å–æ–¹å¼ã€‚
        """
        if file_name.endswith('.pdf'): return cls.read_pdf(file_stream)
        elif file_name.endswith('.md'): return cls.read_markdown(file_stream)
        elif file_name.endswith('.txt'): return cls.read_text(file_stream)
        else: logging.warning(f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_name}"); return ""
    @staticmethod
    def chunk_text(text: str, max_token_len: int = 600, cover_content: int = 150) -> List[str]:
        """
        å°†é•¿æ–‡æœ¬æŒ‰æœ€å¤§tokenæ•°åˆ†å—ï¼Œæ”¯æŒé‡å ã€‚
        """
        chunks = []
        tokens = enc.encode(text)
        i = 0
        while i < len(tokens):
            end = min(i + max_token_len, len(tokens))
            chunk_tokens = tokens[i:end]
            chunk_text = enc.decode(chunk_tokens)
            chunks.append(chunk_text)
            i += (max_token_len - cover_content)
        return chunks

class ServiceClient:
    """
    æœåŠ¡è°ƒç”¨å·¥å…·ç±»ï¼Œè´Ÿè´£ä¸Embeddingå’ŒLLMæœåŠ¡äº¤äº’ã€‚
    """
    @staticmethod
    def get_embeddings(texts: List[str]) -> List[List[float]]:
        """
        è°ƒç”¨EmbeddingæœåŠ¡ï¼Œå°†æ–‡æœ¬æ‰¹é‡è½¬ä¸ºå‘é‡ã€‚
        """
        try:
            response = requests.post(EMBEDDING_SERVER_URL, json={"texts": texts}, timeout=60)
            response.raise_for_status()
            return response.json()["embeddings"]
        except requests.exceptions.RequestException as e:
            logging.error(f"è°ƒç”¨EmbeddingæœåŠ¡å¤±è´¥: {e}"); return []
    @staticmethod
    def generate_response(prompt: str) -> str:
        """
        è°ƒç”¨LLMæœåŠ¡ï¼Œç”Ÿæˆé—®é¢˜çš„å›ç­”ã€‚
        """
        try:
            response = requests.post(LLM_SERVER_URL, json={"prompt": prompt}, timeout=None)
            response.raise_for_status()
            return response.json()["response"]
        except requests.exceptions.RequestException as e:
            logging.error(f"è°ƒç”¨LLMæœåŠ¡å¤±è´¥: {e}"); return f"é”™è¯¯ï¼šæ— æ³•è¿æ¥åˆ°LLMæœåŠ¡ã€‚ {e}"

class MilvusClient:
    """
    Milvus æ•°æ®åº“æ“ä½œå·¥å…·ç±»ï¼Œæ”¯æŒé›†åˆåˆ›å»ºã€æ’å…¥ã€æ£€ç´¢ã€‚
    """
    def __init__(self, host, port):
        """
        åˆå§‹åŒ–Milvusè¿æ¥ã€‚
        """
        from pymilvus import connections, utility, FieldSchema, CollectionSchema, DataType, Collection
        self.connections, self.utility, self.Collection = connections, utility, Collection
        self.DataType, self.FieldSchema, self.CollectionSchema = DataType, FieldSchema, CollectionSchema
        for i in range(20):
            try:
                self.connections.connect("default", host=host, port=port)
                logging.info("âœ… Milvusè¿æ¥æˆåŠŸã€‚"); return
            except Exception as e:
                logging.warning(f"Milvusè¿æ¥å°è¯• {i+1}/20 å¤±è´¥ï¼Œæ­£åœ¨é‡è¯•... Error: {e}"); time.sleep(5)
        raise ConnectionError("é”™è¯¯ï¼šå¤šæ¬¡å°è¯•åæ— æ³•è¿æ¥åˆ°Milvusã€‚")
    def create_or_get_collection(self, collection_name: str, dim: int = 768) -> 'Collection':
        """
        åˆ›å»ºæˆ–è·å–æŒ‡å®šåç§°çš„Milvusé›†åˆã€‚
        """
        if self.utility.has_collection(collection_name): return self.Collection(collection_name)
        fields = [ self.FieldSchema(name="pk", dtype=self.DataType.VARCHAR, is_primary=True, auto_id=True, max_length=100),
                   self.FieldSchema(name="text", dtype=self.DataType.VARCHAR, max_length=65535),
                   self.FieldSchema(name="embedding", dtype=self.DataType.FLOAT_VECTOR, dim=dim) ]
        schema = self.CollectionSchema(fields, "RAGçŸ¥è¯†åº“é›†åˆ")
        collection = self.Collection(name=collection_name, schema=schema)
        index_params = {"index_type": "IVF_FLAT", "metric_type": "L2", "params": {"nlist": 1024}}
        collection.create_index(field_name="embedding", index_params=index_params)
        return collection
    def insert(self, collection_name: str, texts: List[str], vectors: List[List[float]]):
        """
        å‘æŒ‡å®šé›†åˆæ’å…¥æ–‡æœ¬åŠå…¶å‘é‡ã€‚
        """
        collection = self.create_or_get_collection(collection_name)
        collection.insert([texts, vectors]); collection.flush()
    def search(self, collection_name: str, query_vector: List[List[float]], top_k: int = 3) -> List[str]:
        """
        æ£€ç´¢ä¸æŸ¥è¯¢å‘é‡æœ€ç›¸ä¼¼çš„æ–‡æœ¬ã€‚
        """
        if not self.utility.has_collection(collection_name): return ["é”™è¯¯ï¼šçŸ¥è¯†åº“é›†åˆä¸å­˜åœ¨ã€‚"]
        collection = self.Collection(collection_name); collection.load()
        search_params = {"metric_type": "L2", "params": {"nprobe": 10}}
        results = collection.search(data=query_vector, anns_field="embedding", param=search_params, limit=top_k, output_fields=["text"])
        return [hit.entity.get('text') for hit in results[0]] if results else []


# --- RAGæ ¸å¿ƒæµç¨‹ç¼–æ’ (ä¸ä¹‹å‰ç›¸åŒï¼Œæ— éœ€æ”¹åŠ¨) ---
PROMPT_TEMPLATE = """ä½¿ç”¨ä»¥ä¸‹ä¸Šä¸‹æ–‡æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚å¦‚æœä½ ä¸çŸ¥é“ç­”æ¡ˆï¼Œè¯·è¾“å‡ºâ€œæˆ‘ä¸çŸ¥é“â€ã€‚æ€»æ˜¯ä½¿ç”¨ä¸­æ–‡å›ç­”ã€‚
é—®é¢˜: {question}
å¯å‚è€ƒçš„ä¸Šä¸‹æ–‡ï¼š
Â·Â·Â·
{context}
Â·Â·Â·
å¦‚æœç»™å®šçš„ä¸Šä¸‹æ–‡æ— æ³•è®©ä½ åšå‡ºå›ç­”ï¼Œè¯·å›ç­”â€œæ•°æ®åº“ä¸­æ²¡æœ‰è¿™ä¸ªå†…å®¹ï¼Œä½ ä¸çŸ¥é“â€ã€‚
æœ‰ç”¨çš„å›ç­”:"""

def execute_rag_pipeline(files: List[str], query: str) -> str:
    """
    RAGæ ¸å¿ƒæµç¨‹ï¼šæ–‡ä»¶ä¸Šä¼ ã€åˆ†å—ã€å‘é‡åŒ–ã€å…¥åº“ã€æ£€ç´¢ã€ç”Ÿæˆå›ç­”ã€‚
    :param files: æ–‡ä»¶è·¯å¾„åˆ—è¡¨
    :param query: ç”¨æˆ·é—®é¢˜
    :return: æœ€ç»ˆç”Ÿæˆçš„å›ç­”
    """
    logging.info("=============================================")
    logging.info("          å¼€å§‹æ‰§è¡ŒRAGå·¥ä½œæµ          ")
    logging.info("=============================================")
    # 1. åˆå§‹åŒ–å®¢æˆ·ç«¯
    milvus_client = MilvusClient(host=MILVUS_HOST, port=MILVUS_PORT)
    from botocore.exceptions import ClientError
    import boto3
    try:
        # åˆå§‹åŒ–MinIOå®¢æˆ·ç«¯
        minio_client = boto3.client('s3', endpoint_url=f'http://{MINIO_HOST}', aws_access_key_id=MINIO_ACCESS_KEY, aws_secret_access_key=MINIO_SECRET_KEY)
        try:
            # æ£€æŸ¥æ¡¶æ˜¯å¦å­˜åœ¨ï¼Œä¸å­˜åœ¨åˆ™åˆ›å»º
            minio_client.head_bucket(Bucket=MINIO_BUCKET_NAME)
        except ClientError as e:
            if e.response['Error']['Code'] == '404': minio_client.create_bucket(Bucket=MINIO_BUCKET_NAME)
            else: raise
    except Exception as e:
        error_msg = f"âŒ MinIOå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}"; logging.error(error_msg); return error_msg
    # 2. æ–‡ä»¶å¤„ç†ã€å‘é‡åŒ–å¹¶å­˜å…¥Milvus
    collection_name = f"rag_session_{datetime.now().strftime('%Y%m%d%H%M%S')}"
    all_chunks = []
    for file_path in files:
        file_name = os.path.basename(file_path)
        try:
            # ä¸Šä¼ æ–‡ä»¶åˆ°MinIO
            with open(file_path, "rb") as f: minio_client.upload_fileobj(f, MINIO_BUCKET_NAME, file_name)
            # ä»MinIOä¸‹è½½å¹¶å¤„ç†æ–‡ä»¶å†…å®¹
            response = minio_client.get_object(Bucket=MINIO_BUCKET_NAME, Key=file_name)
            content = FileProcessor.read_file_content(response['Body'], file_name)
            # æ–‡æœ¬åˆ†å—
            chunks = FileProcessor.chunk_text(content)
            all_chunks.extend(chunks)
        except Exception as e:
            error_msg = f"å¤„ç†æ–‡ä»¶ '{file_name}' æ—¶å‡ºé”™: {e}"; logging.error(error_msg); return error_msg
    if not all_chunks: error_msg = "âŒ æœªèƒ½ä»ä»»ä½•æ–‡ä»¶ä¸­æå–æ–‡æœ¬å—ã€‚"; logging.error(error_msg); return error_msg
    # æ–‡æœ¬å‘é‡åŒ–
    chunk_vectors = ServiceClient.get_embeddings(all_chunks)
    if not chunk_vectors: error_msg = "âŒ å‘é‡åŒ–å¤±è´¥ï¼Œè¯·æ£€æŸ¥EmbeddingæœåŠ¡ã€‚"; logging.error(error_msg); return error_msg
    # å…¥åº“
    milvus_client.insert(collection_name, all_chunks, chunk_vectors)
    # 3. æ£€ç´¢
    query_vector = ServiceClient.get_embeddings([query])
    if not query_vector: error_msg = "âŒ ç”¨æˆ·é—®é¢˜å‘é‡åŒ–å¤±è´¥ã€‚"; logging.error(error_msg); return error_msg
    retrieved_docs = milvus_client.search(collection_name, query_vector)
    # 4. ç”Ÿæˆå›ç­”
    context = "\n---\n".join(retrieved_docs)
    prompt = PROMPT_TEMPLATE.format(question=query, context=context)
    logging.info(prompt)
    final_response = ServiceClient.generate_response(prompt)
    logging.info("=============================================")
    logging.info("              RAGå·¥ä½œæµæ‰§è¡Œå®Œæ¯•              ")
    logging.info("=============================================")
    return final_response


# --- Streamlit ç•Œé¢å°è£… ---

def run_streamlit_app():
    """
    ä¸»å‡½æ•°ï¼Œç”¨äºæ¸²æŸ“Streamlitç•Œé¢å¹¶å¤„ç†ç”¨æˆ·äº¤äº’ã€‚
    """
    # é¡µé¢åŸºç¡€é…ç½®
    st.set_page_config(page_title="åˆ†å¸ƒå¼RAGåº”ç”¨", layout="wide")
    st.title("ğŸš€ åˆ†å¸ƒå¼RAGåº”ç”¨")
    st.markdown("ä¸Šä¼ æ–‡ä»¶å¹¶æé—®ï¼Œç³»ç»Ÿå°†åŸºäºæ–‡ä»¶å†…å®¹ï¼Œé€šè¿‡åˆ†å¸ƒå¼çš„Embeddingå’ŒLLMæœåŠ¡ç”Ÿæˆå›ç­”ã€‚")

    # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€ï¼Œç”¨äºä¿å­˜å›ç­”
    if "response" not in st.session_state:
        st.session_state.response = "è¯·åœ¨ä¸‹æ–¹æäº¤é—®é¢˜å’Œæ–‡ä»¶ï¼Œæˆ‘ä¼šåœ¨è¿™é‡Œç»™å‡ºå›ç­”..."

    # --- ç•Œé¢å¸ƒå±€ ---
    with st.form("rag_form"):
        query = st.text_input(
            "è¯·è¾“å…¥ä½ çš„é—®é¢˜:",
            placeholder="ä¾‹å¦‚ï¼šè¿™ç¯‡æŠ¥å‘Šçš„æ ¸å¿ƒç»“è®ºæ˜¯ä»€ä¹ˆï¼Ÿ"
        )
        uploaded_files = st.file_uploader(
            "ä¸Šä¼ æ–‡ä»¶ï¼ˆæ”¯æŒ .md, .txt, .pdfï¼‰ï¼Œå¯å¤šé€‰:",
            accept_multiple_files=True,
            type=['md', 'txt', 'pdf']
        )
        submit_button = st.form_submit_button("æäº¤é—®é¢˜å’Œæ–‡ä»¶")

    # --- é€»è¾‘å¤„ç† ---
    if submit_button:
        if not query:
            st.error("é”™è¯¯ï¼šè¯·è¾“å…¥æ‚¨çš„é—®é¢˜ã€‚")
        elif not uploaded_files:
            st.error("é”™è¯¯ï¼šè¯·ä¸Šä¼ è‡³å°‘ä¸€ä¸ªæ–‡ä»¶ã€‚")
        else:
            temp_file_paths = []
            try:
                with st.spinner("ç³»ç»Ÿæ­£åœ¨å¤„ç†ä¸­ï¼Œè¯·ç¨å€™..."):
                    for uploaded_file in uploaded_files:
                        with tempfile.NamedTemporaryFile(delete=False, suffix=f"_{uploaded_file.name}") as tmp_file:
                            tmp_file.write(uploaded_file.getvalue())
                            temp_file_paths.append(tmp_file.name)
                    
                    logging.info(f"Streamlit æ¥æ”¶åˆ°æŸ¥è¯¢: '{query}' å’Œ {len(temp_file_paths)} ä¸ªæ–‡ä»¶ã€‚")
                    
                    final_response = execute_rag_pipeline(files=temp_file_paths, query=query)
                    
                    # æ›´æ–°ä¼šè¯çŠ¶æ€ä¸­çš„å›ç­”
                    st.session_state.response = final_response

            except Exception as e:
                st.session_state.response = f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}"
                logging.error(f"Streamlit UIå±‚æ•è·åˆ°å¼‚å¸¸: {e}")
            finally:
                # æ— è®ºæˆåŠŸä¸å¦ï¼Œéƒ½è¦æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                for path in temp_file_paths:
                    if os.path.exists(path):
                        os.remove(path)
                        logging.info(f"å·²æ¸…ç†ä¸´æ—¶æ–‡ä»¶: {path}")

    # --- æ˜¾ç¤ºå›ç­”åŒºåŸŸ ---
    st.subheader("æ¨¡å‹çš„å›ç­”:")
    st.text_area("å›ç­”å†…å®¹", value=st.session_state.response, height=400, disabled=True, label_visibility="collapsed")


# --- ä¸»ç¨‹åºå…¥å£ ---
if __name__ == "__main__":
    # å¯åŠ¨Streamlit WebæœåŠ¡
    logging.info("æ­£åœ¨å¯åŠ¨ Streamlit Web UI...")
    run_streamlit_app()