# 智能交通监控：端到端的多任务感知与追踪模型

---

## 目录

- [项目背景](#项目背景)
- [需求描述](#需求描述)
- [数据集](#数据集)
- [验收标准](#验收标准)

---

## 项目背景
智能交通监控对于当前复杂的交通环境而言具备重要意义。

### 1. 2D目标检测
- 🚨**感知维度融合**：同步处理目标检测（车辆/行人）、道路结构理解（车道线/可行驶区域）、动态目标跟踪（运动轨迹预测）等多模态信息。
- 🚗**实时性**：高效的推理能力对于实际部署而言意义重大。
- 📊**国产化替代**：英伟达方案存在硬件断供风险，基于昇腾芯片+MindSpore的方案国产化率达100%。

### 2. 多任务检测头
- **YOLOP**：(YOLOv5、YOLOv7)面向自动驾驶场景的多任务感知模型，能够同时完成目标检测。
、可行驶区域分割和车道线检测三大核心任务。其核心思想是通过共享主干网络提取通用特征，再通过不同的任务头实现多任务协同学习，兼顾实时性与精度。
- **A-YOLOM**：基于YOLOv8的多任务感知模型。

### 3. 目标追踪
- **DeepSORT**：基于外观特征（ReID）与运动预测（卡尔曼滤波）的多级关联算法，通过融合外观相似度和运动一致性实现高精度长时跟踪，适合复杂遮挡场景但对计算资源要求较高。
- **ByteTrack**：通过两次数据关联（先匹配高分检测框再匹配低分框）最大化利用检测结果的轻量级算法，无需特征模型，在保持实时性的同时显著提升遮挡场景的轨迹连贯性，更适合边缘设备部署。

### 4. MindSpore
- **MindSpore**：MindSpore 是由华为开发的全场景 AI 计算框架，支持从端侧到云端的深度学习模型高效训练、推理及部署，特别针对昇腾芯片优化，提供自动并行、动静态图结合等特性，助力开发者快速实现高性能、低成本的 AI 应用开发。

---

---
## 需求描述

### 整体描述
基于MindSpore框架的YOLOv12多任务感知系统，通过集成目标检测、可行驶区域分割、车道线识别及跟踪技术，实现高效实时的全栈环境感知，为监控系统提供低延迟、高精度的视觉解决方案。

### 基本目标 使用MindSpore与华为昇腾完成模型建立与训练
### 目标1 多任务感知系统
### 目标2 感知系统可视化UI
### 目标3 检测紧急车道违规并识别阻碍紧急车辆的车辆
### 目标4 分析基于车道的交通流速和拥堵情况，以确定交通状况(车道，可行驶区域，目标检测)
### 目标5 对车辆进行计数并对类型进行分类，以提供有关不同车辆类型的数据
### 目标6 对可疑车辆进行跟踪

---
## 数据集
- **BDD100k**
- **COCO2017**
---


---
## 验收标准

### COCO2017验收指标
在使用640*640分辨率下
- **FLOPs(G)**： 小于等于 10
- **params(M)**：小于等于5
- **map50-95**： 大于等于 39%
- **FPS**: 在同等推理设备下不小于YOLOv12n的80%
---


