{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 设置比赛所需要的环境\n",
    "**因为每次重启netobook后都会设置新的环境，利用jupyter脚本可以一键执行，非常方便**\n",
    "## 其基本过程如下：\n",
    "- 1. mindspore安装\n",
    "- 2. mindformers安装\n",
    "- 3. 模型权重和tokenizer文件准备\n",
    "- 4. 数据集准备（这一步可以直接下载Mindrecord格式的数据集）\n",
    "- 5. 开始微调\n",
    "- 6. 模型合并\n",
    "- 7. 原有能力评估\n",
    "- 8. 微调结果测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Mindspore安装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install mindspore==2.3.0RC2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Mindformers安装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "wget https://2024-ascend-innovation-contest-mindspore.obs.cn-southwest-2.myhuaweicloud.com/topic2-finetune/mindformers.zip\n",
    "unzip mindformers.zip\n",
    "cd mindformers/\n",
    "bash build.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export  PYTHONPATH=\"${PYTHONPATH}:/home/ma-user/work/mindformers/\"\n",
    "pip install tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.模型权重和tokenizer文件准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /home/ma-user/work/\n",
    "wget https://2024-ascend-innovation-contest-mindspore.obs.cn-southwest-2.myhuaweicloud.com/topic2-finetune/llama3-8B.ckpt\n",
    "wget https://2024-ascend-innovation-contest-mindspore.obs.cn-southwest-2.myhuaweicloud.com/topic2-finetune/tokenizer.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.数据集准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /home/ma-user/work/\n",
    "wget https://2024-ascend-innovation-contest-mindspore.obs.cn-southwest-2.myhuaweicloud.com/topic2-finetune/train.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /home/ma-user/work\n",
    "wget https://2024-ascend-innovation-contest-mindspore.obs.cn-southwest-2.myhuaweicloud.com/topic2-finetune/train-data-conversation.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**也可以下载MindRecord数据集**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "wget https://2024-ascend-innovation-contest-mindspore.obs.cn-southwest-2.myhuaweicloud.com/topic2-finetune/train-fastchat256-mindrecore.zip\n",
    "unzip train-fastchat256-mindrecore.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**处理自己抽取出的数据集**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /home/ma-user/work/\n",
    "python data_converter.py --data_path /home/ma-user/work/math_problem/90k-train-data-conversation.json --output_path /home/ma-user/work/math_problem/90k-train-data-conversation.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export PYTHONPATH=\"${PYTHONPATH}:/home/ma-user/work/mindformers/\"\n",
    "pip install tiktoken\n",
    "cd /home/ma-user/work/mindformers/research/llama3\n",
    "python llama_preprocess.py \\\n",
    "--dataset_type qa \\\n",
    "--input_glob /home/ma-user/work/math_problem/110k-train-data-conversation-v3.json \\\n",
    "--model_file /home/ma-user/work/tokenizer.model \\\n",
    "--seq_length 256 \\\n",
    "--output_file /home/ma-user/work/math_problem/110k-train-fastchat256.mindrecord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 开始微调"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4卡微调"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../scripts/msrun_launcher.sh: line 119: ulimit: max user processes: cannot modify limit: Operation not permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Command: msrun --worker_num=4    --local_worker_num=4    --master_port=8118    --log_dir=./output/msrun_log    --join=False    --cluster_time_out=600 llama3/run_llama3.py --config /home/ma-user/work/run_llama3_8b_2024-07-31-v1.yaml --load_checkpoint /home/ma-user/work/llama3-8B.ckpt --auto_trans_ckpt False --use_parallel True --run_mode finetune --train_data /home/ma-user/work/math_problem/110k-train-fastchat256.mindrecord\n",
      "Please check log files in ./output/msrun_log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "[WARNING] ME(2955757:281473427976368,MainProcess):2024-07-31-10:41:53.531.723 [mindspore/parallel/cluster/process_entity/_api.py:210] Start worker process with rank id:0, log file:./output/msrun_log/worker_0.log. Environment variable [RANK_ID] is exported.\n",
      "[WARNING] ME(2955757:281473427976368,MainProcess):2024-07-31-10:41:53.691.351 [mindspore/parallel/cluster/process_entity/_api.py:210] Start worker process with rank id:1, log file:./output/msrun_log/worker_1.log. Environment variable [RANK_ID] is exported.\n",
      "[WARNING] ME(2955757:281473427976368,MainProcess):2024-07-31-10:41:53.890.532 [mindspore/parallel/cluster/process_entity/_api.py:210] Start worker process with rank id:2, log file:./output/msrun_log/worker_2.log. Environment variable [RANK_ID] is exported.\n",
      "[WARNING] ME(2955757:281473427976368,MainProcess):2024-07-31-10:41:54.270.78 [mindspore/parallel/cluster/process_entity/_api.py:210] Start worker process with rank id:3, log file:./output/msrun_log/worker_3.log. Environment variable [RANK_ID] is exported.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd /home/ma-user/work/mindformers/research/\n",
    "bash ../scripts/msrun_launcher.sh \\\n",
    "\"llama3/run_llama3.py \\\n",
    "--config /home/ma-user/work/run_llama3_8b_2024-07-31-v1.yaml \\\n",
    "--load_checkpoint /home/ma-user/work/llama3-8B.ckpt \\\n",
    "--auto_trans_ckpt False \\\n",
    "--use_parallel True \\\n",
    "--run_mode finetune \\\n",
    "--train_data /home/ma-user/work/math_problem/110k-train-fastchat256.mindrecord\" 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../scripts/msrun_launcher.sh: line 119: ulimit: max user processes: cannot modify limit: Operation not permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Command: msrun --worker_num=4    --local_worker_num=4    --master_port=8118    --log_dir=./output/msrun_log    --join=False    --cluster_time_out=600 llama3/run_llama3.py --config /home/ma-user/work/run_llama3_8b_2024-07-29-ptuningv2.yaml --load_checkpoint /home/ma-user/work/llama3-8B.ckpt --auto_trans_ckpt False --use_parallel True --run_mode finetune --train_data /home/ma-user/work/math_problem/90k-train-fastchat256.mindrecord\n",
      "Please check log files in ./output/msrun_log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "[WARNING] ME(7649:281472947482800,MainProcess):2024-07-30-16:27:29.330.203 [mindspore/parallel/cluster/process_entity/_api.py:210] Start worker process with rank id:0, log file:./output/msrun_log/worker_0.log. Environment variable [RANK_ID] is exported.\n",
      "[WARNING] ME(7649:281472947482800,MainProcess):2024-07-30-16:27:29.535.067 [mindspore/parallel/cluster/process_entity/_api.py:210] Start worker process with rank id:1, log file:./output/msrun_log/worker_1.log. Environment variable [RANK_ID] is exported.\n",
      "[WARNING] ME(7649:281472947482800,MainProcess):2024-07-30-16:27:29.757.517 [mindspore/parallel/cluster/process_entity/_api.py:210] Start worker process with rank id:2, log file:./output/msrun_log/worker_2.log. Environment variable [RANK_ID] is exported.\n",
      "[WARNING] ME(7649:281472947482800,MainProcess):2024-07-30-16:27:29.934.582 [mindspore/parallel/cluster/process_entity/_api.py:210] Start worker process with rank id:3, log file:./output/msrun_log/worker_3.log. Environment variable [RANK_ID] is exported.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd /home/ma-user/work/mindformers/research/\n",
    "bash ../scripts/msrun_launcher.sh \\\n",
    "\"llama3/run_llama3.py \\\n",
    "--config /home/ma-user/work/run_llama3_8b_2024-07-29-ptuningv2.yaml \\\n",
    "--load_checkpoint /home/ma-user/work/llama3-8B.ckpt \\\n",
    "--auto_trans_ckpt False \\\n",
    "--use_parallel True \\\n",
    "--run_mode finetune \\\n",
    "--train_data /home/ma-user/work/math_problem/90k-train-fastchat256.mindrecord\" 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.模型合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src_ckpt_strategy: /home/ma-user/work/mindformers/research/output/strategy/merged_ckpt_strategy.ckpt\n",
      "dst_ckpt_strategy: None\n",
      "src_ckpt_dir: /home/ma-user/work/mindformers/research/output/checkpoint/\n",
      "dst_ckpt_dir: /home/ma-user/work/mycheckpoint/\n",
      "prefix: 2024-07-30-lora-llama3-\n",
      "......Start transform......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(21102:281473055338672,MainProcess):2024-07-30-12:02:55.812.921 [mindspore/parallel/_parallel_serialization.py:396] The parameter scale_sense is not in src_strategy.\n",
      "[WARNING] ME(21102:281473055338672,MainProcess):2024-07-30-12:05:04.406.678 [mindspore/parallel/_parallel_serialization.py:396] The parameter global_step is not in src_strategy.\n",
      "[WARNING] ME(21102:281473055338672,MainProcess):2024-07-30-12:05:04.964.422 [mindspore/parallel/_parallel_serialization.py:396] The parameter epoch_num is not in src_strategy.\n",
      "[WARNING] ME(21102:281473055338672,MainProcess):2024-07-30-12:05:04.964.628 [mindspore/parallel/_parallel_serialization.py:396] The parameter step_num is not in src_strategy.\n",
      "[WARNING] ME(21102:281473055338672,MainProcess):2024-07-30-12:05:04.964.706 [mindspore/parallel/_parallel_serialization.py:396] The parameter loss_scale is not in src_strategy.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "......Transform succeed!......\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd /home/ma-user/work/mindformers/\n",
    "python mindformers/tools/transform_ckpt.py \\\n",
    "--src_ckpt_strategy /home/ma-user/work/mindformers/research/output/strategy/ \\\n",
    "--src_ckpt_dir /home/ma-user/work/mindformers/research/output/checkpoint/ \\\n",
    "--dst_ckpt_dir /home/ma-user/work/mycheckpoint/ \\\n",
    "--prefix \"2024-07-30-lora-llama3-\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.原有能力评估\n",
    "**下载评估数据集**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /home/ma-user/work/origin_dataset/\n",
    "wget https://2024-ascend-innovation-contest-mindspore.obs.cn-southwest-2.myhuaweicloud.com/topic2-finetune/squad1.1.zip\n",
    "unzip squad1.1.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**将数据处理为标准格式Mindrecord数据**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /home/ma-user/work/mindformers/mindformers/tools/dataset_preprocess/llama/\n",
    "python squad_data_process.py \\\n",
    "--input_file /home/ma-user/work/origin_dataset//dev-v1.1.json \\\n",
    "--output_file /home/ma-user/work/origin_dataset/squad8192.mindrecord \\\n",
    "--mode eval \\\n",
    "--max_length 8192 \\\n",
    "--tokenizer_type \"llama3-8B\" > /home/ma-user/work/origin_dataset/test_eval_base.log 2>&1 &"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**评估模型的原有能力**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "wget https://2024-ascend-innovation-contest-mindspore.obs.cn-southwest-2.myhuaweicloud.com/topic2-finetune/run_llama3_8b_8k_800T_A2_64G_lora_256_base_eval.yaml -P /home/ma-user/work/mindformers/research/llama3/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /home/ma-user/work/mindformers/ \n",
    "python run_mindformer.py \\\n",
    "--config research/llama3/run_llama3_8b_8k_800T_A2_64G_lora_256_base_eval.yaml \\\n",
    "--eval_dataset_dir /home/ma-user/work/origin_dataset/squad8192.mindrecord \\\n",
    "--run_mode eval \\\n",
    "--load_checkpoint /home/ma-user/work/mycheckpoint/rank_0/2024-07-30-lora-llama3-0.ckpt \\\n",
    "--epochs 1 \\\n",
    "--batch_size 1 \\\n",
    "--use_parallel False \\\n",
    "--device_id 0 | tee /home/ma-user/work/origin_dataset/2024-07-30_log.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**这里在测试的时候，因为需要测试5个模型文件，比较耗时，使用4卡机器可以并行测试**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 测试模型-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /home/ma-user/work/mindformers/ \n",
    "python run_mindformer.py \\\n",
    "--config research/llama3/run_llama3_8b_8k_800T_A2_64G_lora_256_base_eval.yaml \\\n",
    "--eval_dataset_dir /home/ma-user/work/origin_dataset/squad8192.mindrecord \\\n",
    "--run_mode eval \\\n",
    "--load_checkpoint /home/ma-user/work/mycheckpoint/rank_0/2024-07-301-lora-llama3-0.ckpt \\\n",
    "--epochs 1 \\\n",
    "--batch_size 1 \\\n",
    "--use_parallel False \\\n",
    "--device_id 4 | tee /home/ma-user/work/origin_dataset/2024-07-31-0_log.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 测试模型-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /home/ma-user/work/mindformers/ \n",
    "python run_mindformer.py \\\n",
    "--config research/llama3/run_llama3_8b_8k_800T_A2_64G_lora_256_base_eval.yaml \\\n",
    "--eval_dataset_dir /home/ma-user/work/origin_dataset/squad8192.mindrecord \\\n",
    "--run_mode eval \\\n",
    "--load_checkpoint /home/ma-user/work/mycheckpoint/rank_0/2024-07-31-lora-llama3-1.ckpt \\\n",
    "--epochs 1 \\\n",
    "--batch_size 1 \\\n",
    "--use_parallel False \\\n",
    "--device_id 5 | tee /home/ma-user/work/origin_dataset/2024-07-30-1_log.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 测试模型-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /home/ma-user/work/mindformers/ \n",
    "python run_mindformer.py \\\n",
    "--config research/llama3/run_llama3_8b_8k_800T_A2_64G_lora_256_base_eval.yaml \\\n",
    "--eval_dataset_dir /home/ma-user/work/origin_dataset/squad8192.mindrecord \\\n",
    "--run_mode eval \\\n",
    "--load_checkpoint /home/ma-user/work/mycheckpoint/rank_0/2024-07-31-lora-llama3-2.ckpt \\\n",
    "--epochs 1 \\\n",
    "--batch_size 1 \\\n",
    "--use_parallel False \\\n",
    "--device_id 6 | tee /home/ma-user/work/origin_dataset/2024-07-31-2_log.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 测试模型-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /home/ma-user/work/mindformers/ \n",
    "python run_mindformer.py \\\n",
    "--config research/llama3/run_llama3_8b_8k_800T_A2_64G_lora_256_base_eval.yaml \\\n",
    "--eval_dataset_dir /home/ma-user/work/origin_dataset/squad8192.mindrecord \\\n",
    "--run_mode eval \\\n",
    "--load_checkpoint /home/ma-user/work/mycheckpoint/rank_0/2024-07-31-lora-llama3-3.ckpt \\\n",
    "--epochs 1 \\\n",
    "--batch_size 1 \\\n",
    "--use_parallel False \\\n",
    "--device_id 7 | tee /home/ma-user/work/origin_dataset/2024-07-31-3_log.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 微调结果测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "wget https://2024-ascend-innovation-contest-mindspore.obs.cn-southwest-2.myhuaweicloud.com/topic2-finetune/run_llama3_test.py -P /home/ma-user/work/mindformers/research/llama3/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://2024-ascend-innovation-contest-mindspore.obs.cn-southwest-2.myhuaweicloud.com/topic2-finetune/run_llama3_8b_8k_800T_A2_64G_lora_256_eval.yaml -P /home/ma-user/work/mindformers/research/llama3/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /home/ma-user/work/mindformers/research\n",
    "python llama3/run_llama3_test.py \\\n",
    "--config llama3/run_llama3_8b_8k_800T_A2_64G_lora_256_eval.yaml \\\n",
    "--run_mode predict \\\n",
    "--use_parallel False \\\n",
    "--load_checkpoint /home/ma-user/work/mindformers/research/output/checkpoint/rank_0/new_lora_checkpoint_0.ckpt \\\n",
    "--vocab_file /home/ma-user/work/tokenizer.model \\\n",
    "--auto_trans_ckpt False \\\n",
    "--input_dir \"/home/ma-user/work/math_eval.json\" | tee /home/ma-user/work/origin_dataset/2024-07-30_math_problem_dataset_eval_log.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将数学问题处理为标准数据格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://pip.modelarts.private.com:8888/repository/pypi/simple\n",
      "Requirement already satisfied: tiktoken in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (0.7.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from tiktoken) (2024.5.15)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from tiktoken) (2.27.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken) (2.10)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.0.1; however, version 24.2 is available.\n",
      "You should consider upgrading via the '/home/ma-user/anaconda3/envs/MindSpore/bin/python3.9 -m pip install --upgrade pip' command.\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed 30000 records.\n",
      "Transform finished, output files refer: /home/ma-user/work/math_problem/30k-test-fastchat256.mindrecord\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "export PYTHONPATH=\"${PYTHONPATH}:/home/ma-user/work/mindformers/\"\n",
    "pip install tiktoken\n",
    "cd /home/ma-user/work/mindformers/research/llama3\n",
    "python llama_preprocess.py \\\n",
    "--dataset_type qa \\\n",
    "--input_glob /home/ma-user/work/math_problem/30k-test-data-conversation.json \\\n",
    "--model_file /home/ma-user/work/tokenizer.model \\\n",
    "--seq_length 256 \\\n",
    "--output_file /home/ma-user/work/math_problem/30k-test-fastchat256.mindrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 16:08:40,716 - mindformers[mindformers/tools/utils.py:153] - INFO - set output path to '/home/ma-user/work/mindformers/output'\n",
      "2024-07-30 16:08:40,739 - mindformers[mindformers/trainer/trainer.py:919] - INFO - Load configs in /home/ma-user/work/mindformers/configs/general/run_general_task.yaml to build trainer.\n",
      "2024-07-30 16:08:40,740 - mindformers[mindformers/trainer/trainer.py:949] - INFO - ..........Init Config..........\n",
      "2024-07-30 16:08:40,740 - mindformers[mindformers/core/parallel_config.py:45] - INFO - initial recompute_config from dict: {'recompute': True, 'select_recompute': False, 'parallel_optimizer_comm_recompute': False, 'mp_comm_recompute': True, 'recompute_slice_activation': True}\n",
      "2024-07-30 16:08:40,740 - mindformers[mindformers/core/parallel_config.py:51] - INFO - initial parallel_config from dict: {'data_parallel': 1, 'model_parallel': 4, 'pipeline_stage': 1, 'use_seq_parallel': False, 'micro_batch_num': 1, 'vocab_emb_dp': True, 'gradient_aggregation_group': 4}\n",
      "2024-07-30 16:08:40,741 - mindformers[mindformers/tools/utils.py:153] - INFO - set output path to '/home/ma-user/work/mindformers/output'\n",
      "2024-07-30 16:08:40,741 - mindformers[mindformers/tools/utils.py:168] - INFO - set strategy path to './output/strategy/ckpt_strategy_rank_0.ckpt'\n",
      "2024-07-30 16:08:40,741 - mindformers[mindformers/trainer/base_trainer.py:85] - INFO - Now Running Task is: text_generation, Model is: llama3_8b\n",
      "2024-07-30 16:08:40,741 - mindformers[mindformers/trainer/base_trainer.py:111] - WARNING - Input model name is not in the supported list or unspecified.\n",
      "2024-07-30 16:08:40,742 - mindformers[mindformers/trainer/base_trainer.py:112] - WARNING - See the list of supported task and model name: ['baichuan2_13b', 'baichuan2_7b', 'baichuan_7b', 'bloom_176b', 'bloom_560m', 'bloom_65b', 'bloom_7.1b', 'codegeex2_6b', 'codellama_34b', 'common', 'deepseek_33b', 'glm2_6b', 'glm2_6b_lora', 'glm2_6b_ptuning2', 'glm3_6b', 'glm_6b', 'glm_6b_chat', 'glm_6b_lora', 'glm_6b_lora_chat', 'gpt2', 'gpt2_13b', 'gpt2_52b', 'gpt2_lora', 'gpt2_xl', 'gpt2_xl_lora', 'internlm_7b', 'internlm_7b_lora', 'llama2_13b', 'llama2_70b', 'llama2_7b', 'llama_13b', 'llama_65b', 'llama_7b', 'llama_7b_lora', 'pangualpha_13b', 'pangualpha_2_6b', 'qwen_7b', 'qwen_7b_lora', 'skywork_13b', 'yi_34b', 'yi_6b', 'ziya_13b']\n",
      "2024-07-30 16:08:40,742 - mindformers[mindformers/trainer/base_trainer.py:113] - WARNING - The default model config: /home/ma-user/work/mindformers/configs/gpt2/run_gpt2.yaml will now be used for the text_generation task \n",
      "2024-07-30 16:08:40,742 - mindformers[mindformers/trainer/trainer.py:1004] - INFO - ..........Init Model..........\n",
      "2024-07-30 16:08:40,742 - mindformers[mindformers/trainer/trainer.py:335] - INFO - ==========Trainer Init Success!==========\n",
      "2024-07-30 16:08:40,743 - mindformers[mindformers/trainer/trainer.py:1004] - INFO - ..........Init Model..........\n",
      "2024-07-30 16:08:40,743 - mindformers[mindformers/trainer/base_trainer.py:213] - INFO - The current parallel mode is stand_alone, batch size per card will not be changed: batch_size_per_card = 1\n",
      "2024-07-30 16:08:40,743 - mindformers[mindformers/trainer/base_trainer.py:217] - INFO - global_batch_size = batch_size_per_card * device_num * gradient_accumulation_steps = 1 = 1 * 1 * 1\n",
      "2024-07-30 16:08:40,743 - mindformers[mindformers/trainer/base_trainer.py:226] - INFO - parallel_config will be change to default config: [ParallelConfig]\n",
      "_recompute:[ParallelConfig]\n",
      "_recompute:True\n",
      "_select_recompute:False\n",
      "_select_comm_recompute:False\n",
      "_parallel_optimizer_comm_recompute:False\n",
      "_mp_comm_recompute:True\n",
      "_recompute_slice_activation:True\n",
      "\n",
      "select_recompute:False\n",
      "use_seq_parallel:False\n",
      "_optimizer_shard:None\n",
      "_gradient_aggregation_group:4\n",
      "_embed_dp_mp_config:[ParallelConfig]\n",
      "_dp_mp_config:[ParallelConfig]\n",
      "_data_parallel:1\n",
      "_model_parallel:1\n",
      "use_seq_parallel:False\n",
      "select_recompute:False\n",
      "\n",
      "_vocab_emb_dp:True\n",
      "use_seq_parallel:False\n",
      "select_recompute:False\n",
      "\n",
      "_pp_config:[ParallelConfig]\n",
      "_pipeline_stage:1\n",
      "_micro_batch_num:1\n",
      "\n",
      "_moe_config:[ParallelConfig]\n",
      "_dpmp:[ParallelConfig]\n",
      "_data_parallel:1\n",
      "_model_parallel:1\n",
      "use_seq_parallel:False\n",
      "select_recompute:False\n",
      "\n",
      "_expert_parallel:1\n",
      "use_seq_parallel:False\n",
      "select_recompute:False\n",
      "\n",
      ".\n",
      "2024-07-30 16:08:40,744 - mindformers[mindformers/trainer/base_trainer.py:796] - INFO - .........Build Dataset For Evaluate..........\n",
      "2024-07-30 16:08:40,744 - mindformers[mindformers/trainer/base_trainer.py:360] - INFO - .........Build Dataset From Config..........\n",
      "2024-07-30 16:08:40,744 - mindformers[mindformers/trainer/base_trainer.py:379] - INFO - For evaluate phase, batch size for eval dataset is 1, different from training, not multiplied by micro_batch_num, micro_batch_interleave_num and gradient_accumulation_steps\n",
      "2024-07-30 16:08:40,744 - mindformers[mindformers/dataset/causal_language_model_dataset.py:166] - INFO - Now Create Causal Language Model Dataset.\n",
      "2024-07-30 16:08:40,751 - mindformers[mindformers/trainer/base_trainer.py:799] - INFO - Create evaluate dataset finish, dataset size:60000\n",
      "2024-07-30 16:08:40,752 - mindformers[mindformers/tools/check_rules.py:102] - WARNING - Flash attention only support training process for now, disable use_flash_attention in eval mode.\n",
      "2024-07-30 16:08:40,755 - mindformers[mindformers/trainer/base_trainer.py:387] - INFO - .........Build Network From Config..........\n",
      "2024-07-30 16:08:40,755 - mindformers[mindformers/version_control.py:61] - INFO - The Cell Reuse compilation acceleration feature is not supported when the environment variable ENABLE_CELL_REUSE is 0 or MindSpore version is earlier than 2.1.0 or stand_alone mode or pipeline_stages <= 1\n",
      "2024-07-30 16:08:40,756 - mindformers[mindformers/version_control.py:65] - INFO - \n",
      "The current ENABLE_CELL_REUSE=0, please set the environment variable as follows: \n",
      "export ENABLE_CELL_REUSE=1 to enable the Cell Reuse compilation acceleration feature.\n",
      "2024-07-30 16:08:40,756 - mindformers[mindformers/version_control.py:71] - INFO - The Cell Reuse compilation acceleration feature does not support single-card mode.This feature is disabled by default. ENABLE_CELL_REUSE=1 does not take effect.\n",
      "2024-07-30 16:08:40,756 - mindformers[mindformers/version_control.py:74] - INFO - The Cell Reuse compilation acceleration feature only works in pipeline parallel mode(pipeline_stage>1).Current pipeline stage=1, the feature is disabled by default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] DEVICE(665579,ffff8920f0b0,python):2024-07-30-16:08:41.027.192 [mindspore/ccsrc/plugin/device/ascend/hal/device/ascend_memory_adapter.cc:95] Initialize] Reserved memory size for other components(536870912) is less than recommend size(1890134528), It may lead to Out Of Memory in HCCL or other components, Please double check context key 'variable_memory_max_size'/'max_device_memory'\n",
      "[WARNING] ME(665579:281472982380720,MainProcess):2024-07-30-16:09:03.105.907 [mindspore/ops/primitive.py:203] The in_strategy/in_layout of the operator in your network will not take effect in stand_alone mode. This means the the shard function called in the network is ignored. \n",
      "If you want to enable it, please use semi auto or auto parallel mode by context.set_auto_parallel_context(parallel_mode=ParallelMode.SEMI_AUTO_PARALLEL or context.set_auto_parallel_context(parallel_mode=ParallelMode.AUTO_PARALLEL)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 16:09:12,688 - mindformers[mindformers/models/llama/llama_transformer.py:468] - INFO - MoE config is None, use normal FFN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(665579:281472982380720,MainProcess):2024-07-30-16:09:12.689.834 [mindspore/common/_decorator.py:40] 'Parameter' is deprecated from version 2.3 and will be removed in a future version, use 'add_pipeline_stage' instead.\n",
      "[WARNING] ME(665579:281472982380720,MainProcess):2024-07-30-16:09:12.689.965 [mindspore/common/parameter.py:806] This interface may be deleted in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 16:09:15,596 - mindformers[mindformers/models/llama/llama_transformer.py:468] - INFO - MoE config is None, use normal FFN\n",
      "2024-07-30 16:09:18,305 - mindformers[mindformers/models/llama/llama_transformer.py:468] - INFO - MoE config is None, use normal FFN\n",
      "2024-07-30 16:09:21,014 - mindformers[mindformers/models/llama/llama_transformer.py:468] - INFO - MoE config is None, use normal FFN\n",
      "2024-07-30 16:09:23,807 - mindformers[mindformers/models/llama/llama_transformer.py:468] - INFO - MoE config is None, use normal FFN\n",
      "2024-07-30 16:09:26,619 - mindformers[mindformers/models/llama/llama_transformer.py:468] - INFO - MoE config is None, use normal FFN\n",
      "2024-07-30 16:09:29,374 - mindformers[mindformers/models/llama/llama_transformer.py:468] - INFO - MoE config is None, use normal FFN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 41 leaked semaphore objects to clean up at shutdown\n",
      "  warnings.warn('resource_tracker: There appear to be %d '\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd /home/ma-user/work/mindformers/ \n",
    "python run_mindformer.py \\\n",
    "--config research/llama3/run_llama3_8b_math_problem_eval.yaml \\\n",
    "--eval_dataset_dir /home/ma-user/work/math_problem/30k-test-fastchat256.mindrecord \\\n",
    "--run_mode eval \\\n",
    "--load_checkpoint /home/ma-user/work/mycheckpoint/rank_0/2024-07-29-lora-llama3-0.ckpt \\\n",
    "--epochs 1 \\\n",
    "--batch_size 1 \\\n",
    "--use_parallel False \\\n",
    "--device_id 0 | tee /home/ma-user/work/origin_dataset/2024-07-29-mathproblem_log.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作品上传"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:List OBS time cost: 1.09 seconds.\n"
     ]
    }
   ],
   "source": [
    "import moxing as mox\n",
    "\n",
    "#上传一个OBS文件夹sub_dir_0，从Notebook上传至OBS\n",
    "mox.file.copy_parallel('/home/ma-user/work/20240718-output', 'obs://xxx/xxx/result-2')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
