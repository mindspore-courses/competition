# 作品报告

## （1）微调算法介绍，包含使用的微调数据集规模的预处理方式


LoRA 微调算法原理及介绍
LoRA（Low-Rank Adaptation）是一种用于大语言模型（LLM）微调的技术，通过引入
低秩矩阵实现高效的参数更新。以下是 LoRA 微调算法的原理及其详细介绍。

LoRA 微调算法原理

1. 低秩近似

在传统的全模型微调中，需要调整模型中所有的参数，这对于大型语言模型来说非常耗
时且资源密集。LoRA 的核心思想是利用低秩矩阵来近似原始权重的变化。具体来说，
对于模型中的一个权重矩阵 W ，用两个低秩矩阵 A 和 B 来表示其变化。

即： ΔW=A×B\Delta W = A \times BΔW=A×B 其中，A 和 B 是低秩矩阵，通常 A 的
维度为 d×rd \times rd×r，B 的维度为 r×kr \times kr×k，其中 r 远小于 d 和 k，即秩
r 很低。

2. 参数注入

原始权重矩阵 W 在微调过程中被修改为： W′=W+ΔW=W+A×BW' = W + \Delta W = W + A \times BW′=W+ΔW=W+A×B 这种方法允许通过学习 A 和 B 来调整模型的行
为，而不必直接修改 W。

3. 训练

由于 A 和 B 的参数量远少于 W，微调过程变得更加高效。尤其是在处理大规模模型
时，这种方法显著减少了计算资源和时间开销。

4. 结果
LoRA 可以方便地应用于各种预训练模型，只需在预训练模型的特定层上添加低秩矩阵。
这样，LoRA 既能保持模型的原有性能，又能通过微调适应新任务。

LoRA 微调算法流程



1. 初始化低秩矩阵

根据模型的结构和微调需求，初始化低秩矩阵 A 和 B。

2. 插入低秩矩阵

将低秩矩阵插入到模型的特定层中，用于调整权重。

3. 训练过程

在微调过程中，仅更新 A 和 B 的参数，而保持其他参数固，从而调整 A 和 B。

4. 模型更新

训练完成后，利用调整后的 A 和 B 来更新模型的权重矩阵，得到最终的微调模型。


数据处理部分：

首先在原有的数据集中进行去重，得到新的数据 A，在新的数据中选出五千条数据。

在选出的五千条数据中，对回答部分添加解题的中间步骤，最终得出本次训练使用的数

据集。



## （2）超参配置介绍说明

在训练过程中，增大学习率为 1e-4，batchsize 改为 8，使用单卡训练，lora 训练参

数的 rank 设定为 4，alpha 设定为为 8。



## （3）微调后的权重文件链接，

https://zzqms.obs.cn-southwest-2.myhuaweicloud.com/model/mydata_5k_256_8_add_4.ckpt


## （4）模型微调后原有能力评估得分；

在推理原有能力时，修改了配置文件，添加了 min_token = 1 得出原能力分数：F1

score: 58.75865618394202, Em score: 44.17029511369134。 

## （5）数据处理部分的代码
去除重复数据的代码：fiter.py

对数据添加解题步骤的代码：add_solution.py